{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bddfdef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in c:\\users\\bruno queles\\anaconda3\\lib\\site-packages (37.4.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\bruno queles\\anaconda3\\lib\\site-packages (from faker) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5f8399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas as bibliotecas importadas com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import faker\n",
    "import sqlalchemy\n",
    "import pyodbc # Este é o mais provável de precisar instalar\n",
    "print(\"Todas as bibliotecas importadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735dc3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testando conexão com o SQL Server ---\n",
      "Conexão com o SQL Server estabelecida com sucesso!\n",
      "\n",
      "--- Extraindo operações da Logistica.Operacoes para gerar o histórico ---\n",
      "Total de 49371 operações encontradas em Logistica.Operacoes para gerar histórico.\n",
      "\n",
      "--- Gerando e inserindo histórico de ocorrências para as operações ---\n",
      "Total de 177002 registros de histórico gerados.\n",
      "--- Inserindo 177002 dados na tabela Logistica.HistoricoOperacoes (append). ---\n",
      "Todos os 177002 dados foram inseridos com sucesso na tabela Logistica.HistoricoOperacoes!\n"
     ]
    }
   ],
   "source": [
    "# logistics_flow_simulator.py - Script para Recarregar APENAS HistoricoOperacoes\n",
    "\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from sqlalchemy import create_engine, text\n",
    "import urllib # Importe urllib para codificar a string de conexão\n",
    "\n",
    "# --- Configurações do Banco de Dados ---\n",
    "DB_SERVER = 'BRUNO\\\\SQLEXPRESS'\n",
    "DB_DATABASE = 'LoggiConnect'\n",
    "DB_USERNAME = 'BRUNO\\\\Bruno Queles'\n",
    "DB_PASSWORD = ''\n",
    "DB_DRIVER = '{ODBC Driver 17 for SQL Server}'\n",
    "\n",
    "# --- Inicializa o Faker (usado aqui apenas para funções internas de data/hora) ---\n",
    "fake = Faker('pt_BR')\n",
    "\n",
    "# --- Dados de Referência (usados na geração do histórico) ---\n",
    "STATUS_IDS = {\n",
    "    'Coleta Realizada': 10,\n",
    "    'Em Trânsito': 11,\n",
    "    'Objeto em Rota de Entrega': 12,\n",
    "    'Entrega Realizada': 13,\n",
    "    'Atraso na Entrega': 1,\n",
    "    'Extravio de Encomenda': 2,\n",
    "    'Avaria no Produto': 3,\n",
    "    'Destinatário Ausente': 4,\n",
    "    'Endereço Incorreto': 5,\n",
    "    'Recusa da Mercadoria': 6,\n",
    "    'Coleta Não Realizada': 7,\n",
    "    'Roubo / Furto': 8,\n",
    "    'Restrição de Entrega': 9,\n",
    "    'Objeto Devolvido': 14,\n",
    "    'Problema Fiscal': 15,\n",
    "}\n",
    "\n",
    "# Lista de Cidades por UF (simplificada para o exemplo)\n",
    "CIDADES_POR_UF = {\n",
    "    'SP': ['São Paulo', 'Campinas', 'Guarulhos', 'Ribeirão Preto', 'Santos'],\n",
    "    'RJ': ['Rio de Janeiro', 'Niterói', 'Duque de Caxias', 'Nova Iguaçu', 'Campos dos Goytacazes'],\n",
    "    'MG': ['Belo Horizonte', 'Uberlândia', 'Contagem', 'Juiz de Fora', 'Montes Claros'],\n",
    "    'ES': ['Vitória', 'Vila Velha', 'Serra', 'Cariacica', 'Linhares']\n",
    "}\n",
    "UFS_SUDESTE = ['SP', 'RJ', 'MG', 'ES']\n",
    "\n",
    "# --- Função para Gerar Histórico de Ocorrências para uma Operação ---\n",
    "def generate_history_for_operation(operation_row):\n",
    "    history = []\n",
    "    id_operacao = operation_row['id_operacao']\n",
    "    codigo_rastreio = operation_row['codigo_rastreio']\n",
    "    data_pedido = operation_row['data_pedido']\n",
    "    data_previsao_entrega = operation_row['data_previsao_entrega']\n",
    "    data_entrega_real = operation_row['data_entrega_real'] \n",
    "    status_final_id = operation_row['status_entrega_id']\n",
    "    origem_cidade = operation_row['origem_cidade']\n",
    "    destino_cidade = operation_row['destino_cidade']\n",
    "    origem_uf = operation_row['origem_uf']\n",
    "    destino_uf = operation_row['destino_uf']\n",
    "\n",
    "    status_flow = [\n",
    "        (STATUS_IDS['Coleta Realizada'], 'Coleta do produto realizada com sucesso.'),\n",
    "        (STATUS_IDS['Em Trânsito'], 'Objeto em trânsito entre unidades.'),\n",
    "        (STATUS_IDS['Objeto em Rota de Entrega'], 'Objeto saiu para entrega final.'),\n",
    "        (STATUS_IDS['Entrega Realizada'], 'Entrega finalizada com sucesso.')\n",
    "    ]\n",
    "\n",
    "    local_eventos = {\n",
    "        STATUS_IDS['Coleta Realizada']: origem_cidade + ' / ' + origem_uf,\n",
    "        STATUS_IDS['Entrega Realizada']: destino_cidade + ' / ' + destino_uf,\n",
    "    }\n",
    "\n",
    "    if isinstance(data_pedido, datetime):\n",
    "        current_history_datetime = data_pedido\n",
    "    elif isinstance(data_pedido, pd.Timestamp):\n",
    "        current_history_datetime = data_pedido.to_pydatetime()\n",
    "    else:\n",
    "        current_history_datetime = datetime.combine(data_pedido, datetime.min.time())\n",
    "    \n",
    "    history.append({\n",
    "        'id_operacao': id_operacao,\n",
    "        'codigo_rastreio': codigo_rastreio,\n",
    "        'id_tipo_ocorrencia': STATUS_IDS['Coleta Realizada'],\n",
    "        'data_hora_evento': current_history_datetime,\n",
    "        'local_evento': local_eventos[STATUS_IDS['Coleta Realizada']],\n",
    "        'observacoes': 'Coleta do produto realizada com sucesso.'\n",
    "    })\n",
    "\n",
    "    if status_final_id == STATUS_IDS['Entrega Realizada']:\n",
    "        for status_id, obs_text in status_flow[1:-1]:\n",
    "            days_passed = random.randint(1, 3)\n",
    "            proposed_datetime = current_history_datetime + timedelta(days=days_passed, hours=random.randint(1, 23), minutes=random.randint(1, 59))\n",
    "            \n",
    "            if data_entrega_real:\n",
    "                real_delivery_datetime = datetime.combine(data_entrega_real, datetime.max.time())\n",
    "                if proposed_datetime > real_delivery_datetime:\n",
    "                    proposed_datetime = real_delivery_datetime - timedelta(hours=random.randint(1,48), minutes=random.randint(1,59))\n",
    "                    if proposed_datetime < current_history_datetime:\n",
    "                        proposed_datetime = current_history_datetime + timedelta(minutes=random.randint(5,60))\n",
    "            \n",
    "            current_history_datetime = proposed_datetime\n",
    "\n",
    "            if status_id == STATUS_IDS['Em Trânsito']:\n",
    "                intermediate_city = random.choice(CIDADES_POR_UF[random.choice(UFS_SUDESTE)])\n",
    "                local_evento_intermediate = intermediate_city + ' / ' + random.choice(UFS_SUDESTE)\n",
    "            elif status_id == STATUS_IDS['Objeto em Rota de Entrega']:\n",
    "                local_evento_intermediate = destino_cidade + ' / ' + destino_uf\n",
    "            else:\n",
    "                local_evento_intermediate = fake.city() + ' / ' + fake.state_abbr()\n",
    "\n",
    "            history.append({\n",
    "                'id_operacao': id_operacao,\n",
    "                'codigo_rastreio': codigo_rastreio,\n",
    "                'id_tipo_ocorrencia': status_id,\n",
    "                'data_hora_evento': current_history_datetime,\n",
    "                'local_evento': local_evento_intermediate,\n",
    "                'observacoes': obs_text\n",
    "            })\n",
    "\n",
    "        final_delivery_datetime = datetime.combine(data_entrega_real, fake.time_object()) if data_entrega_real else current_history_datetime\n",
    "        if final_delivery_datetime < current_history_datetime:\n",
    "            final_delivery_datetime = current_history_datetime + timedelta(minutes=random.randint(5, 60))\n",
    "        if final_delivery_datetime.date() < data_pedido.date():\n",
    "            final_delivery_datetime = datetime.combine(data_pedido.date(), datetime.min.time()) + timedelta(days=random.randint(1,3), hours=random.randint(1,23), minutes=random.randint(1,59))\n",
    "            if final_delivery_datetime < current_history_datetime:\n",
    "                final_delivery_datetime = current_history_datetime + timedelta(minutes=random.randint(5, 60))\n",
    "\n",
    "\n",
    "        history.append({\n",
    "            'id_operacao': id_operacao,\n",
    "            'codigo_rastreio': codigo_rastreio,\n",
    "            'id_tipo_ocorrencia': status_final_id,\n",
    "            'data_hora_evento': final_delivery_datetime,\n",
    "            'local_evento': local_eventos[STATUS_IDS['Entrega Realizada']],\n",
    "            'observacoes': 'Entrega finalizada com sucesso.'\n",
    "        })\n",
    "    else:\n",
    "        problem_occurrence_datetime = fake.date_time_between(\n",
    "            start_date=current_history_datetime,\n",
    "            end_date=datetime.combine(data_previsao_entrega, datetime.max.time()) + timedelta(days=random.randint(1, 10)),\n",
    "            tzinfo=None\n",
    "        )\n",
    "        if problem_occurrence_datetime < current_history_datetime:\n",
    "            problem_occurrence_datetime = current_history_datetime + timedelta(minutes=random.randint(5,60))\n",
    "            \n",
    "        if status_final_id == STATUS_IDS['Atraso na Entrega']:\n",
    "            obs = 'Entrega atrasada devido a imprevistos operacionais.'\n",
    "            loc = fake.city() + ' / ' + fake.state_abbr()\n",
    "        elif status_final_id == STATUS_IDS['Destinatário Ausente']:\n",
    "            obs = 'Destinatário ausente na tentativa de entrega.'\n",
    "            loc = destino_cidade + ' / ' + destino_uf\n",
    "        elif status_final_id == STATUS_IDS['Problema Fiscal']:\n",
    "            obs = 'Problema fiscal detectado na mercadoria. Retida em fiscalização.'\n",
    "            loc = fake.city() + ' / ' + fake.state_abbr()\n",
    "        else:\n",
    "            obs = fake.text(max_nb_chars=100)\n",
    "            loc = fake.city() + ' / ' + fake.state_abbr()\n",
    "\n",
    "        history.append({\n",
    "            'id_operacao': id_operacao,\n",
    "            'codigo_rastreio': codigo_rastreio,\n",
    "            'id_tipo_ocorrencia': status_final_id,\n",
    "            'data_hora_evento': problem_occurrence_datetime,\n",
    "            'local_evento': loc,\n",
    "            'observacoes': obs\n",
    "        })\n",
    "    \n",
    "    history.sort(key=lambda x: x['data_hora_evento'])\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "# --- Função para Obter Conexão com o Banco de Dados ---\n",
    "def get_db_connection():\n",
    "    params = urllib.parse.quote_plus(\n",
    "        f\"DRIVER={DB_DRIVER};\"\n",
    "        f\"SERVER={DB_SERVER};\"\n",
    "        f\"DATABASE={DB_DATABASE};\"\n",
    "        f\"Trusted_Connection=yes;\"\n",
    "    )\n",
    "    conn_str = f\"mssql+pyodbc:///?odbc_connect={params}\"\n",
    "    engine = create_engine(conn_str)\n",
    "    return engine\n",
    "\n",
    "# --- Bloco Principal: Simulação de Carga (Apenas Histórico) ---\n",
    "if __name__ == \"__main__\":\n",
    "    engine = get_db_connection()\n",
    "\n",
    "    print(\"\\n--- Testando conexão com o SQL Server ---\")\n",
    "    try:\n",
    "        with engine.connect() as connection:\n",
    "            result = connection.execute(text(\"SELECT 1 AS ConnectionTest\")).scalar()\n",
    "            if result == 1:\n",
    "                print(\"Conexão com o SQL Server estabelecida com sucesso!\")\n",
    "            else:\n",
    "                print(\"Erro inesperado ao testar a conexão com o SQL Server.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao conectar ao SQL Server: {e}\")\n",
    "        print(\"Verifique seu servidor, nome da instância, nome do banco de dados e driver ODBC.\")\n",
    "        exit()\n",
    "\n",
    "    # --- 1. Extrair os dados necessários da Logistica.Operacoes (já populada e correta) ---\n",
    "    print(\"\\n--- Extraindo operações da Logistica.Operacoes para gerar o histórico ---\")\n",
    "    # Buscamos os dados completos da Operacoes, pois precisamos de todos os detalhes\n",
    "    # para gerar um histórico realista (data_pedido, data_previsao_entrega, etc.)\n",
    "    query_operations = \"\"\"\n",
    "    SELECT\n",
    "        id_operacao,\n",
    "        id_cliente,\n",
    "        id_transportadora,\n",
    "        data_pedido,\n",
    "        data_previsao_entrega,\n",
    "        data_entrega_real,\n",
    "        origem_uf,\n",
    "        origem_cidade,\n",
    "        destino_uf,\n",
    "        destino_cidade,\n",
    "        peso_kg,\n",
    "        volume_m3,\n",
    "        valor_frete,\n",
    "        status_entrega_id,\n",
    "        codigo_rastreio\n",
    "    FROM Logistica.Operacoes;\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df_operations_for_history = pd.read_sql(query_operations, engine)\n",
    "        print(f\"Total de {len(df_operations_for_history)} operações encontradas em Logistica.Operacoes para gerar histórico.\")\n",
    "        if df_operations_for_history.empty:\n",
    "            print(\"Nenhuma operação em Logistica.Operacoes para gerar histórico. Encerrando o script.\")\n",
    "            exit()\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao extrair dados da Logistica.Operacoes para geração de histórico: {e}\")\n",
    "        exit()\n",
    "\n",
    "    # --- 2. Geração e Carga do Histórico de Ocorrências (Logistica.HistoricoOperacoes) ---\n",
    "    print(\"\\n--- Gerando e inserindo histórico de ocorrências para as operações ---\")\n",
    "    all_history_data = []\n",
    "    \n",
    "    for index, row in df_operations_for_history.iterrows():\n",
    "        all_history_data.extend(generate_history_for_operation(row))\n",
    "    \n",
    "    df_history = pd.DataFrame(all_history_data)\n",
    "    \n",
    "    # Remove a coluna 'id_historico' se ela for auto-incremento no seu DB\n",
    "    if 'id_historico' in df_history.columns:\n",
    "        df_history = df_history.drop(columns=['id_historico'])\n",
    "\n",
    "    print(f\"Total de {len(df_history)} registros de histórico gerados.\")\n",
    "\n",
    "    print(f\"--- Inserindo {len(df_history)} dados na tabela Logistica.HistoricoOperacoes (append). ---\")\n",
    "    try:\n",
    "        df_history.to_sql(\n",
    "            name='HistoricoOperacoes',\n",
    "            con=engine,\n",
    "            schema='Logistica',\n",
    "            if_exists='append',\n",
    "            index=False,\n",
    "            chunksize=500\n",
    "        )\n",
    "        print(f\"Todos os {len(df_history)} dados foram inseridos com sucesso na tabela Logistica.HistoricoOperacoes!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar ou inserir histórico de ocorrências: {e}\")\n",
    "        print(\"Certifique-se de que Logistica.HistoricoOperacoes foi truncada antes desta carga e que o esquema da tabela está correto (incluindo 'codigo_rastreio').\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9178d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
